General Overview

We aim to create a complete observability system for an application developed with FastAPI. This system will be responsible for collecting and analyzing metrics, logs, and traces. To achieve this, we will leverage the following set of tools:

* Otel-collector: A tool for collecting data and sending it to various systems.
* Clickhouse: A high-performance database designed for storing large datasets.
* Uptrace: A tool for tracing requests and observing system performance.
* Prometheus: A tool for collecting and storing metrics.
* Grafana: A tool for visualizing dashboards and graphs for data analysis.
* PostgreSQL: A powerful relational database used for storing structured data such as user data or application settings.
* Redis: A fast in-memory database used for caching data and improving system performance. In this project, Redis will be used for temporary data storage and to speed up data access.
* Tempo: A tool for collecting and managing trace data.
* Loki: A tool for collecting and storing logs. Loki integrates well with Prometheus and Grafana, allowing us to store and display logs generated by the FastAPI app.

Project Structure

observability/
├─ app/
│  ├─ main.py
│  └─ requirements.txt
├─ Dockerfile
├─ docker-compose.yaml
├─ otel-collector.yaml
└─ uptrace.yaml
└─ prometheus.yaml
└─ tempo.yaml
└─ loki-config.yaml


---

Example FastAPI Service with OTLP Data Sending

File app/main.py:

# app/main.py
import time, random
from fastapi import FastAPI
from contextlib import asynccontextmanager
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode, SpanKind
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor

tracer = trace.get_tracer("fastapi-app", "1.0.0")

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield

app = FastAPI(title="FastAPI + OTLP via Collector", lifespan=lifespan)
FastAPIInstrumentor.instrument_app(app)

@app.get("/health")
def health():
    return {"ok": True}

@app.get("/work")
def work(q: int = 5):
    with tracer.start_as_current_span("simulate-work", kind=SpanKind.INTERNAL) as span:
        delay = random.uniform(0.05, 0.25) * q
        time.sleep(delay)
        span.set_attribute("work.q", q)
        span.set_attribute("work.delay_sec", round(delay, 3))
        if delay > 0.9:
            span.set_status(Status(StatusCode.ERROR, "too slow"))
    return {"status": "done", "delay_sec": round(delay, 3)}

Explanation:

1. FastAPI App Creation:
The FastAPI app is created, and it’s instrumented with OpenTelemetry using FastAPIInstrumentor.instrument_app(app). This integration allows us to collect trace data, including latency and performance information.
2. Endpoint /health:
A simple health check endpoint. When a request is made to /health, it responds with { "ok": True }, indicating that the service is running fine.
3. Endpoint /work:
This endpoint simulates a task with a random delay:
  * A span called simulate-work is created to trace the work being done.
  * A random delay between 0.05 and 0.25 seconds is calculated and multiplied by the query parameter q.
  * If the delay exceeds 0.9 seconds, the span is marked as an error.
  * The delay and q values are saved in the span as attributes, which can later be analyzed to identify performance bottlenecks.
4. The collected data, including the delay and q values, is stored in the span and can be used for further performance analysis.

File app/requirements.txt:

fastapi
uvicorn[standard]

opentelemetry-distro
opentelemetry-exporter-otlp
opentelemetry-instrumentation-fastapi
opentelemetry-instrumentation-logging

---

Dockerfile

FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
WORKDIR /app

RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates curl && \
    rm -rf /var/lib/apt/lists/*

COPY app/requirements.txt /app/requirements.txt
RUN python -m venv /opt/venv && . /opt/venv/bin/activate && \
    pip install --no-cache-dir -r /app/requirements.txt

COPY app /app/app
EXPOSE 8000
CMD ["/bin/sh", "-c", ". /opt/venv/bin/activate && \
  opentelemetry-instrument \
    --traces_exporter otlp --metrics_exporter otlp --logs_exporter otlp \
    uvicorn app.main:app --host 0.0.0.0 --port 8000 --log-level info --access-log"]

---

File docker-compose.yaml:

services:
  app:
    image: fastapi-otel:1.0.0
    restart: always
    container_name: fastapi-app
    environment:
      OTEL_SERVICE_NAME: checkout-api
      OTEL_SERVICE_VERSION: "1.0.3"
      DEPLOYMENT_ENVIRONMENT: dev
      OTEL_TRACES_EXPORTER: otlp
      OTEL_EXPORTER_OTLP_PROTOCOL: grpc
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otelcol:4317
      OTEL_EXPORTER_OTLP_HEADERS: uptrace-dsn=http://fastApi_secret@uptrace:80?grpc=4317
      OTEL_LOGS_EXPORTER: otlp
      OTEL_METRICS_EXPORTER: otlp
      OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED: "true"

    ports:
      - "3001:8000"
    depends_on:
      - clickhouse
      - postgres
      - redis
      - uptrace
      - otelcol
    networks:
      - filebeat_custom_network

  clickhouse:
    image: clickhouse/clickhouse-server:25.3.5
    restart: always
    environment:
      CLICKHOUSE_USER: uptrace
      CLICKHOUSE_PASSWORD: uptrace
      CLICKHOUSE_DB: uptrace
    healthcheck:
      test: ['CMD', 'wget', '--spider', '-q', 'localhost:8123/ping']
      interval: 1s
      timeout: 1s
      retries: 30
    volumes:
      - ch_data:/var/lib/clickhouse
    ports:
      - '8123:8123'
      - '9000:9000'
    networks:
      - filebeat_custom_network
  postgres:
    image: postgres:17-alpine
    restart: on-failure
    environment:
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_USER: uptrace
      POSTGRES_PASSWORD: uptrace
      POSTGRES_DB: uptrace
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U uptrace -d uptrace']
      interval: 1s
      timeout: 1s
      retries: 30
    volumes:
      - 'pg_data3:/var/lib/postgresql/data/pgdata'
    ports:
      - '5432:5432'
    networks:
      - filebeat_custom_network
  redis:
    image: redis:6.2.2-alpine
    restart: on-failure
    networks:
      - filebeat_custom_network
  uptrace:
    image: 'uptrace/uptrace:2.0.1'
    restart: on-failure
    environment:
      - UPTRACE_HTTP_COOKIE_SAME_SITE=None
      - UPTRACE_HTTP_CORS_ALLOWED_ORIGINS=http://localhost:14318
    volumes:
      - ./uptrace.yaml:/etc/uptrace/config.yaml
      - ./certs/server.crt:/etc/uptrace/server.crt
      - ./certs/server.key:/etc/uptrace/server.key
    ports:
      - '14317:4317'
      - '14318:80'
    depends_on:
      - clickhouse
      - postgres
      - redis
    networks:
      - filebeat_custom_network
  otelcol:
    image: otel/opentelemetry-collector-contrib:0.123.0
    command: ["--config=/etc/otelcol-contrib/config.yaml"]
    restart: on-failure
    volumes:
      - ./otel-collector.yaml:/etc/otelcol-contrib/config.yaml
    ports:
      - 8888:8888
    depends_on:
      - clickhouse
      - postgres
      - redis
      - uptrace
    networks:
      - filebeat_custom_network
  
  prometheus:
    image: prom/prometheus:v2.36.2
    restart: always
    volumes:
      - ./prometheus.yaml:/etc/prometheus/prometheus.yaml
      - prometheus_data:/prometheus
    ports:
      - 9090:9090
    command:
      - '--config.file=/etc/prometheus/prometheus.yaml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    networks:
      - filebeat_custom_network
    depends_on:
      - otelcol

  grafana:
    image: grafana/grafana:12.0.0
    restart: on-failure
    volumes:
      - ./grafana/datasource.yaml:/etc/grafana/provisioning/datasources/datasource.yaml
      - ./grafana/custom.ini:/etc/grafana/grafana.ini
    ports:
      - '3000:3000'
    extra_hosts:
      - 'host.docker.internal:host-gateway'
    networks:
      - filebeat_custom_network
    depends_on:
      - prometheus

  loki:
    image: grafana/loki:latest
    command: ["-config.file=/etc/loki/loki-config.yaml"]
    ports:
      - 3100:3100
    volumes:
      - ./loki-config.yaml:/etc/loki/loki-config.yaml
      - loki_data:/loki 
    networks:
      - filebeat_custom_network

  tempo:
    image: grafana/tempo:2.5.0
    container_name: tempo
    command: ["-config.file=/etc/tempo/tempo.yaml"]
    restart: on-failure
    ports:
      - "3200:3200"   # HTTP API / Query / health / metrics
      - "4317:4317"   # OTLP gRPC ingest
      - "4318:4318"   # OTLP HTTP ingest
    volumes:
      - ./tempo.yaml:/etc/tempo/tempo.yaml
      - tempo_data:/var/tempo
    networks:
      - filebeat_custom_network
    depends_on:
      - otelcol
    

volumes:
  ch_data:
  pg_data3:
  prometheus_data:
  loki_data:
  tempo_data:


networks:
  filebeat_custom_network:
  



This file includes various services such as FastAPI-app, Clickhouse, Redis, Prometheus, Grafana, Loki, Tempo, Uptrace, and OpenTelemetry Collector (otelcol). Below is an explanation of what each section of the file does:

Service Explanations:

1. FastAPI (app) Service:
  * This service is your FastAPI application, which acts as the main service for processing requests.
  * Environment variables related to OpenTelemetry are set to send trace and metric data to otelcol.
  * This service depends on other services like Clickhouse, Postgres, Redis, Uptrace, and otelcol.
2. Clickhouse:
  * This service is the Clickhouse database, which is used for data storage.
  * Clickhouse is used in this project to store tracing and metric data.
  * It is accessible through ports 8123 and 9000.
3. PostgreSQL:
  * This service is the PostgreSQL database, which is used for storing other types of information.
  * The database settings include the username and password, which are used for communication with other services.
  * PostgreSQL is accessible through port 5432.
4. Redis:
  * This service is Redis, which is used for caching data and improving performance.
  * Redis is used to store temporary or cached data in the project.
5. Uptrace:
  * Uptrace is used for analyzing trace and metric data.
  * This service depends on Clickhouse, Postgres, Redis, and otelcol and collects data from them.
6. OpenTelemetry Collector (otelcol):
  * otelcol is responsible for collecting, processing, and sending trace and metric data.
  * This service collects data from services like FastAPI, Prometheus, Loki, and Uptrace, and sends it to destinations like Clickhouse or Prometheus.
  * It uses port 8888 for communication.
7. Prometheus:
  * Prometheus is a tool for collecting and storing metrics.
  * This service uses the prometheus.yaml file for configuration and collects metric data from other services.
  * It uses port 9090 for access to dashboards and metrics.
8. Grafana:
  * Grafana is used to create dashboards and display data collected from Prometheus.
  * Configuration files related to Grafana, including the datasource and custom settings, are placed in grafana/datasource.yaml and grafana/custom.ini.
  * It uses port 3000 for accessing the dashboards.
9. Loki:
  * Loki is used for collecting and storing logs.
  * This service uses port 3100 for accessing log data.
  * Loki’s configuration is loaded from the loki-config.yaml file.
10. Tempo:
  * Tempo is used for collecting trace data via OTLP (OpenTelemetry Protocol).
  * This service is used to receive data from otelcol and store it.
  * It uses ports 3200, 4317, and 4318 to receive data.

Network and Dependencies Explanation:

* Network (custom_network): All services are placed in a custom network called custom_network to ensure they can easily communicate with each other.
* Volumes: These services use volumes for persistent data storage (e.g., Clickhouse, Prometheus, Loki, and Tempo data).
* Depends_on: The services specify their dependencies. For example, FastAPI must receive support from Clickhouse, Postgres, Redis, Uptrace, and otelcol before starting.

---

File otel-collector.yaml:

processors:
  resourcedetection:
    detectors: [env, system]
  cumulativetodelta: {}
  batch:
    send_batch_size: 10000
    timeout: 10s

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  hostmetrics:
    scrapers:
      cpu: {}
      disk: {}
      filesystem: {}
      load: {}
      memory: {}
      network: {}
      paging: {}

exporters:
  debug: {}
  # Uptrace (OTLP gRPC)
  otlp/uptrace:
    endpoint: uptrace:4317
    tls:
      insecure: true
    headers:
      uptrace-dsn: "http://fastApi_secret@uptrace:80?grpc=4317"
    sending_queue:
      enabled: true
      num_consumers: 4
      queue_size: 10240
    retry_on_failure:
      enabled: true
      initial_interval: 1s
      max_interval: 30s
      max_elapsed_time: 300s

  # Tempo (OTLP gRPC)
  otlp/tempo:
    endpoint: tempo:4317
    tls:
      insecure: true
    sending_queue:
      enabled: true
      num_consumers: 4
      queue_size: 10240
    retry_on_failure:
      enabled: true
      initial_interval: 1s
      max_interval: 30s
      max_elapsed_time: 300s

  loki:
    endpoint: http://loki:3100/loki/api/v1/push
    tls:
      insecure: true

service:
  telemetry:
    metrics:
      readers:
        - pull:
            exporter:
              prometheus:
                host: 0.0.0.0
                port: 8888
  
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp/uptrace, otlp/tempo, debug]
  
    metrics/host:
      receivers: [hostmetrics]
      processors: [cumulativetodelta, batch, resourcedetection]
      exporters: [otlp/uptrace, debug]

    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp/uptrace, loki, debug]

1. Processors:

This section defines the various processes that are performed on the data.

* resourcedetection:
  * This process detects system resource information (such as environment and operating system). It uses two detectors: env and system for detecting resources.
* cumulativetodelta:
  * This process converts cumulative data into delta data (differences).
* batch:
  * Data is sent in batches. Here:
    * send_batch_size: 10000:
      * The maximum size for each batch is 10,000 data points.
    * timeout: 10s:
      * The maximum wait time for sending a batch of data is 10 seconds.

2. Receivers:

This section specifies where the OpenTelemetry Collector will receive data from.

* otlp:
  * This protocol is used to receive trace and metric data from services. There are two different protocols for receiving data:
    * grpc:
      * A protocol for receiving data in gRPC format, which is active on port 4317.
    * http:
      * A protocol for receiving data in HTTP format, which is active on port 4318.
* hostmetrics:
  * This section collects system performance data such as CPU, disk, memory, network, etc.

3. Exporters:

This section specifies where the collected data will be sent.

* debug:
  * Used for debugging and reviewing data in logs. The data is displayed locally in the logs.
* otlp/uptrace:
  * Data is sent to Uptrace via OTLP (OpenTelemetry Protocol). This service is used for analyzing trace and metric data.
    * endpoint: uptrace:4317:
      * Specifies that the data will be sent to the address uptrace on port 4317.
      * Queue and retry settings are also configured for sending data in case of errors.
* otlp/tempo:
  * Data is sent to Tempo. Tempo is a tracing system that collects and stores trace data.
    * endpoint: tempo:4317:
      * Data is sent to the address tempo on port 4317.
* loki:
  * Log data is sent to Loki. Loki is a system for storing and searching logs.
    * endpoint: http://loki:3100/loki/api/v1/push:
      * Data is sent to the address loki on port 3100.

4. Service:

This section specifies how the data is managed and processed.

* telemetry:
  * Settings related to monitoring the performance of the OpenTelemetry Collector itself.
    * metrics:
      * Metrics data related to the Collector itself is available via Prometheus.
* pipelines:
  * Here, data is processed through multiple pipelines and sent to various destinations.
    * traces:
      * Trace data is received via the OTLP protocol, processed, and sent to Uptrace, Tempo, and debug.
    * metrics/host:
      * System metrics data (CPU, memory, etc.) is received from hostmetrics and after processing, it is sent to Uptrace and debug.
    * logs:
      * Log data is received from OTLP and sent to Uptrace, Loki, and debug.



---

File uptrace.yaml:

service:
  env: development
  secret: fastApi_secret

site:
  url: http://localhost:14318
  ingest_url: http://uptrace:80?grpc=4317

listen:
  http:
    addr: :80      # Inside the container
  grpc:
    addr: :4317    # Inside the container

auth: {}

seed_data:
  update: true
  delete: true

  users:
    - key: user1
      name: Admin
      email: admin@uptrace.local
      password: 1qaz!QAZ
      email_confirmed: true

  user_tokens:
    - key: user_token1
      user_key: user1
      token: user1_secret

  orgs:
    - key: org1
      name: Org1

  org_users:
    - key: org_user1
      org_key: org1
      user_key: user1
      role: owner

  projects:
    - key: registrationTools
      name: RegistrationTools
      org_key: org1

  project_tokens:
    - key: registrationTools_token1
      project_key: registrationTools
      token: fastApi_secret

  project_users:
    - key: project_user1
      project_key: registrationTools
      org_user_key: org_user1
      perm_level: admin
  
ch_cluster:
  cluster: uptrace1
  replicated: false
  distributed: false
  shards:
    - replicas:
        - addr: clickhouse:9000
          database: uptrace
          user: uptrace
          password: uptrace
          dial_timeout: 3s
          write_timeout: 5s
          max_retries: 3
          max_execution_time: 15s

pg:
  addr: postgres:5432
  user: uptrace
  password: uptrace
  database: uptrace

ch_schema:
  compression: ZSTD(1)
  spans_index: { storage_policy: default }
  spans_data: { storage_policy: default }
  span_links: { storage_policy: default }
  logs_index: { storage_policy: default }
  logs_data: { storage_policy: default }
  events_index: { storage_policy: default }
  events_data: { storage_policy: default }
  metrics: { storage_policy: default }

redis_cache:
  addrs:
    1: redis:6379
  username: ""
  password: ""
  db: 0

certmagic:
  enabled: false
  staging_ca: false
  http_challenge_addr: :80

mailer:
  smtp:
    enabled: false
    host: localhost
    port: 1025
    username: mailhog
    password: mailhog
    from: no-reply@uptrace.local

spans: {}
span_links: {}
logs: {}
events: {}
metrics: {}
trace: {}
alerting: {}
service_graph: {}
sourcemaps:

self_monitoring:
  dsn: http://fastApi_secret@uptrace:80?grpc=14317
  tls:
   insecure_skip_verify: true

telegram:
  bot_token: ''

logging:
  level: INFO

license:
  key: ''



This configuration is generally for environment settings, databases, users, projects, and other parameters related to Uptrace and its functionality.

Explanation of Different Sections:

1. service:

* env: This option is used to define the execution environment. Here, it is set to development, which means a development environment. For production, this can be changed.
* secret: The secret key used for authentication to Uptrace. This value should be replaced with your own.

2. site:

* url: The main URL for Uptrace. By default, it points to http://localhost:14318.
* ingest_url: The URL for Uptrace to send data via gRPC.

3. listen:

* http.addr: Port 80 for receiving HTTP requests from other services.
* grpc.addr: Port 4317 for receiving trace and metric data via the gRPC protocol.
* tls: Section for TLS settings (for secure communication), which is commented out here.

4. auth:

* This section is for authentication settings. It is empty here, which means authentication is not used.

5. seed_data:

This section is for setting up initial data, which is useful for creating default users and projects if needed.

* update: Specifies whether the data should be updated.
* delete: Specifies whether the previous data should be deleted.
* In this section, users, project tokens, and organizations are defined.

6. ch_cluster:

Settings related to Clickhouse for storing Uptrace data.

* cluster: The name of the Clickhouse cluster.
* replicated: Settings for replication.
* shards: Shards in Clickhouse where the data is stored.

7. pg:

Settings related to PostgreSQL, which is used for storing other data (such as user information).

* addr: The address of the PostgreSQL database.
* user, password, database: Connection details for the database.

8. ch_schema:

Settings for the Clickhouse schema, where the data is stored. This includes data compression and storage policies for different types of data such as traces (spans), logs, and metrics.

9. redis_cache:

Settings related to Redis, which is used for caching temporary data.

* addrs: The address of Redis.
* db: The Redis database to be used.

10. certmagic:

Settings related to TLS certificates for providing secure communication (if enabled).

11. mailer:

Settings related to sending emails. Here, Mailhog is mentioned, which is a tool for testing emails.

12. spans, span_links, logs, events, metrics, trace:

These sections are empty by default and refer to the types of data that can be collected from Uptrace.

13. alerting:

Settings related to alerts. This section can be used to configure alerts for various issues and errors.

14. service_graph:

Settings related to the service graph to display the connections between services and analyze them.

15. sourcemaps:

This section enables or disables Sourcemaps for the frontend. It helps you analyze minified or compressed JavaScript code in its original form.

16. self_monitoring:

This section is for monitoring the performance of Uptrace itself. Uptrace sends its performance data to this project.

17. telegram:

Settings for sending alerts or messages via the Telegram bot.

18. logging:

Log level settings. Here, the log level is set to INFO.

19. license:

Settings related to the license key, which is empty here.



---

File prometheus.yaml:

global:
  scrape_interval: 15s # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s # By default, scrape targets every 15 seconds.
  # scrape_timeout is set to the global default (10s).
  # Attach these labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'uptrace-project'

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 15s
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'otelcol'
    scrape_interval: 10s
    static_configs:
      - targets: ['otelcol:8888']

1. global:

This section contains the default settings used for collecting metric data from various systems.

* scrape_interval: 15s:
  * This setting specifies that, by default, Prometheus collects data from various targets every 15 seconds.
* evaluation_interval: 15s:
  * This setting specifies that Prometheus evaluates alert rules every 15 seconds.
* external_labels:
  * This section allows Prometheus to add labels to time series or alerts. Here, the label monitor: 'uptrace-project' is added to every data point sent to external systems (such as federation systems, remote storage, or Alertmanager).

2. scrape_configs:

This section defines the settings for collecting data from various sources (targets).

- job_name: 'prometheus':

In this section, Prometheus is set to collect its own metric data as a target.

* scrape_interval: 15s:
  * Data from this target is collected every 15 seconds.
* static_configs:
  * This section defines fixed targets for collecting data. Here, the target localhost:9090 is specified, which points to Prometheus itself.

- job_name: 'otelcol':

This section is for collecting metric data from the OpenTelemetry Collector.

* scrape_interval: 10s:
  * Data from this target is collected every 10 seconds.
* static_configs:
  * The target otelcol:8888 is specified, which refers to the OpenTelemetry Collector. This address is used for receiving metric data from otelcol.



---

File loki-config.yaml:

auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096
  http_server_read_timeout: 5m
  http_server_write_timeout: 5m

common:
  instance_addr: 127.0.0.1
  path_prefix: /loki
  replication_factor: 1
  ring:
    kvstore:
      store: memberlist

memberlist:
  join_members: []
  abort_if_cluster_join_fails: false

schema_config:
  configs:
    - from: 2024-01-01
      store: tsdb
      object_store: filesystem
      schema: v13
      index:
        prefix: index_
        period: 24h

storage_config:
  filesystem:
    directory: /loki/chunks
  tsdb_shipper:
    active_index_directory: /loki/index
    cache_location: /loki/index_cache
    cache_ttl: 24h

distributor: {}
ingester:
  chunk_target_size: 1048576
  max_chunk_age: 1h
ruler:
  alertmanager_url: http://localhost:9093
  enable_api: true
query_scheduler: {}
compactor:
  working_directory: /loki/compactor
  compaction_interval: 5m

query_range:
  results_cache:
    cache:
      embedded_cache:
        enabled: true
      max_size_mb: 100
analytics:
  reporting_enabled: false

1. auth_enabled: false:

* This section specifies that authentication for Loki is disabled. This means users can access data without needing to log in or authenticate. If you want to add more security, change this to true and add the authentication settings.

2. server:

Settings related to the Loki server.

* http_listen_port: 3100:
  * The HTTP port that Loki listens to. This port is used for HTTP requests.
* grpc_listen_port: 9096:
  * The gRPC port used for gRPC requests from other services.
* http_server_read_timeout and http_server_write_timeout:
  * Timeout settings for reading and writing HTTP requests (set to 5 minutes here).

3. common:

General settings for the Loki service.

* instance_addr: 127.0.0.1:
  * The IP address that Loki listens on. This is useful if you want to run Loki on a specific server or in a distributed environment.
* path_prefix: /loki:
  * The path prefix used in the URL for accessing Loki.
* replication_factor: 1:
  * The number of data replicas stored in the system. A value of 1 means data only has one copy.
* ring:
  * Configuration related to the ring for distributed storage.
    * kvstore:
    * Settings for distributed state storage (including choosing memberlist as the state storage method).

4. memberlist:

Settings related to memberlist, which is used for managing cluster state and synchronizing data.

* join_members: []:
  * A list of existing cluster members. This is empty, meaning no member is joined to the cluster by default.
* abort_if_cluster_join_fails: false:
  * Specifies whether to stop the process if Loki fails to join the cluster.

5. schema_config:

This section configures the schema for storing data.

* store: tsdb:
  * Uses the TSDB (Time Series Database) system for storing data.
* object_store: filesystem:
  * Data is stored in the filesystem.
* schema: v13:
  * The schema version for storage.
* index:
  * Configures the indexes. Indexes help Loki search data more efficiently.
    * prefix: index_:
    * The prefix for the indexes.
    * period: 24h:
    * Data is indexed on a daily basis.

6. storage_config:

Settings related to data storage.

* filesystem:
  * Location for storing data on disk.
    * directory: /loki/chunks:
    * Loki data is stored at this location.
* tsdb_shipper:
  * Settings for TSDB that help with proper data storage.
    * active_index_directory and cache_location:
    * Locations for storing indexes and cache.
    * cache_ttl: 24h:
    * The TTL for cache (cache expires every 24 hours).

7. distributor:

Settings related to data distribution within the system.

* Here, the settings are empty (perhaps for future configurations or special needs).

8. ingester:

Settings related to ingester, which is responsible for processing and storing logs.

* chunk_target_size: 1048576:
  * The target size for each chunk (the piece of data being stored) in bytes.
* max_chunk_age: 1h:
  * The maximum allowed time for each chunk before it is automatically archived.

9. ruler:

This section is related to alert rules and monitoring.

* alertmanager_url:
  * The URL of Alertmanager used for managing alerts.
* enable_api: true:
  * Enables API access for managing alerts.

10. query_range:

Settings related to querying and searching in Loki.

* results_cache:
  * Cache for query results to improve search speed.
    * enabled: true:
    * Query results caching is enabled.
    * max_size_mb: 100:
    * The maximum cache size is 100 MB.

11. analytics:

Settings related to analytics.

* reporting_enabled: false:
  * Reporting is disabled by default.



---

File tempo.yaml:

server:
  http_listen_port: 3200

distributor:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318

ingester:
  lifecycler:
    ring:
      kvstore:
        store: memberlist
      replication_factor: 1
  max_block_duration: 5m

memberlist:
  bind_port: 7946
  join_members: [] 

compactor:
  compaction:
    compacted_block_retention: 48h

storage:
  trace:
    backend: local
    wal:
      path: /var/tempo/wal
    local:
      path: /var/tempo/blocks

1. server:

* http_listen_port: 3200:
  * The port that the Tempo server uses to receive HTTP requests. Here, port 3200 is set.

2. distributor:

This section is related to the distributor, which collects trace data from services and sends it to the ingester.

* receivers:
  * Specifies the protocols from which trace data should be received:
    * otlp:
      * For receiving trace data from OpenTelemetry.
        * grpc:
          * Port 4317 for receiving gRPC data.
        * http:
          * Port 4318 for receiving HTTP data.

3. ingester:

This section is related to processing and storing the trace data that is received in Tempo.

* lifecycler:
  * Settings related to managing state and synchronizing data in Tempo.
    * ring:
      * Information about synchronizing data across different nodes in the distributed system.
        * kvstore:
          * Uses memberlist for storing the cluster state.
        * replication_factor: 1:
          * The number of data replicas in the cluster. A value of 1 means data only has one copy.
    * max_block_duration: 5m:
      * The maximum duration for each data block before it is automatically moved to another block (5 minutes).

4. memberlist:

This section is related to memberlist settings, which are used for managing cluster state and synchronization between nodes in the system.

* bind_port: 7946:
  * The port used to connect to other nodes in the cluster.
* join_members: []:
  * A list of existing nodes to manually join the cluster. It is empty here, meaning no node is joined to the cluster by default.

5. compactor:

This section is related to compaction, which is used for compressing stored data and removing old data.

* compaction:
  * compacted_block_retention: 48h:
    * The duration for which compacted data is retained. Here, data is kept for 48 hours before it is compressed or removed.

6. storage:

Settings related to how trace data (traces) is stored in Tempo.

* trace:
  * backend: local:
    * Uses local as the data storage system.
  * wal:
    * Related to the Write Ahead Log (WAL) used for temporarily storing data.
      * path: /var/tempo/wal:
        * The location for storing WAL files.
  * local:
    * path: /var/tempo/blocks:
      * The location for storing data blocks in Tempo.



---

Run the project with Docker Compose:

docker compose up -d --build

If the FastAPI image hasn’t been built yet, run the following command first:

docker build -t fastapi-app:latest .

Then run:

docker compose up -d

Testing:

You can test the setup by sending requests to the FastAPI app using:

curl -s "http://localhost:3001/health"
curl -s "http://localhost:3001/work?q=4"

